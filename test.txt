Based on your request to further split the work into three distinct phases, here is the breakdown for three separate Jira tickets.

This structure is highly effective for Agile workflows because it separates **Research (Spike)** from **Execution (Implementation)**, preventing "rabbit holes" where a ticket gets stuck in development because the solution wasn't fully defined yet.

---

### **Ticket 1: The Documentation Ticket (PLOPS-448)**

*Focus: Standardization and Compliance*

**Title:**
`[EKS Runbook] Create Standardized Release Runbook for datadog-agent`

**Description:**
**Objective**
Create a standardized runbook for upgrading the `datadog-agent` in EKS clusters. This document will serve as the Source of Truth for all future agent releases.

**Requirements**

1. **Template:** Must strictly follow `PLC-000: Change Runbook Template`.
2. **Reference:** Use `PLC-002: External-dns Release Runbook` as the gold standard for formatting.
3. **Reuse:** Leverage the `Kubernetes Baseline App Release Excerpt` for generic steps (e.g., ArgoCD syncs) to avoid duplication.

**Acceptance Criteria**

* [ ] **Confluence Page:** A new page exists for the Datadog Agent Release Runbook.
* [ ] **Compliance:** The runbook follows the standard structure (Pre-checks, Execution, Rollback, Post-checks).
* [ ] **Review:** The runbook has been reviewed and approved by Platform Engineers (AF/PLOPS).

---

### **Ticket 2: The Investigation Ticket (New Ticket)**

*Focus: Research & Discovery (Time-boxed Spike)*

**Title:**
`[Spike] Investigate Verification Steps for datadog-agent`

**Description:**
**Context**
Before automating the verification pipeline, we need to identify exactly *how* to verify that `datadog-agent` is healthy. Unlike standard deployments, the agent runs as a DaemonSet and has specific health metrics.

**Goal**
Identify the specific `kubectl` commands, API calls, or log patterns required to confirm the agent is fully functional.

**Output**
A list of verified commands/logic documented in the Jira comments or a design doc, ready to be handed off for implementation.

**Acceptance Criteria**

* [ ] **Commands Identified:** Specific commands to check DaemonSet rollout status and Pod health are identified.
* [ ] **Functional Check:** A method to verify the agent is actually sending metrics/logs (connectivity check) is identified.
* [ ] **Manual Validation:** The identified steps have been manually tested against a live cluster to ensure accuracy.
* [ ] **Edge Cases:** Potential failure scenarios (e.g., node not ready) are noted.

---

### **Ticket 3: The Implementation Ticket (PLOPS-554)**

*Focus: Coding & Automation*
*Blocker: This ticket cannot start until Ticket 2 is complete.*

**Title:**
`[Automation] Implement Verification Pipeline for datadog-agent`

**Description:**
**Objective**
Develop an automated verification script in `ProjectDrgn/platform-automation` based on the findings from the investigation phase.

**Scope**

1. **Scripting:** Write a Python/Shell script that executes the logic defined in the Investigation ticket.
2. **Integration:** Configure this script to run as an **ArgoCD Post-Sync Hook**.
3. **Documentation:** Create a `README.md` explaining how the verification logic works.

**Acceptance Criteria**

* [ ] **Script Created:** A verification script exists in `ProjectDrgn/platform-automation`.
* [ ] **ArgoCD Hook:** The script is successfully triggered by ArgoCD after a deployment.
* [ ] **Pass/Fail Logic:** The script correctly fails the pipeline if the datadog-agent is unhealthy.
* [ ] **Documentation:** `README.md` is updated with verification logic details.
* [ ] **Peer Review:** Code passed PR review.

---

### **Suggested Workflow for You**

1. **Keep PLOPS-448** as is (Runbook).
2. **Create a NEW ticket** for "Investigation" and link it as "Blocks PLOPS-554".
3. **Update PLOPS-554** to be purely "Implementation" (remove the "investigate" lines from its description).