Here is a structured Jira ticket ready for your backlog. I have organized it to clearly explain the **"Why"** (Fail Fast) and the **"How"** (ArgoCD Hooks) to your team.

***

**Title:** Refactor Istio Verification Pipeline: Modularize into ArgoCD Sync Hooks

**Issue Type:** User Story / Improvement
**Priority:** High
**Assignee:** Andy Hsu
**Labels:** `istio`, `argocd`, `reliability`, `automation`

### **Description**

**Context**
Currently, our Istio verification process is a monolithic job running in the `af-toolkit` namespace. It requires manual triggering after we sync `istio-base`, `istiod`, and `istio-ingress`, and after we run the `sequential-restart-all-istio-enabled-services` job.

**The Problem**
1.  **Late Feedback Loop:** We currently verify the control plane *after* we have already restarted workloads. If `istiod` is unhealthy, we risk rolling out broken sidecars to production pods before catching the issue.
2.  **Monolithic Debugging:** If the single verification job fails, it is not immediately clear if the issue is the Control Plane, Ingress, or mTLS without digging into the specific job logs.
3.  **Manual Toil:** The process relies on manual verification steps rather than automated gating within the GitOps pipeline.

**Proposed Solution**
Refactor the monolithic verification script into granular Python scripts and integrate them as **ArgoCD PostSync Hooks**. This moves us to a "Fail Fast" pipeline design.

### **Technical Implementation Plan**

We will split the existing scripts and attach them to the relevant ArgoCD Applications:

**1. Phase 1: Control Plane Gating (Fail Fast)**
* **Script:** Refactor `verify_controlplane.py` (Checks: deployment status, `proxy-status` STALE checks, `istioctl analyze`).
* **Hook Location:** `istiod` Application.
* **Trigger:** `PostSync`
* **Behavior:** If this hook fails, the sync fails. We **stop** here and do not proceed to restart applications.

**2. Phase 2: Ingress Verification**
* **Script:** Extract ingress checks (Gateway status, external connectivity).
* **Hook Location:** `istio-ingress` Application.
* **Trigger:** `PostSync`

**3. Phase 3: Data Plane Verification**
* **Script:** Refactor `check_mtls.py` (Sidecar connectivity) and `check_retry_after.py` (EnvoyFilter logic).
* **Hook Location:** `sequential-restart-all-istio-enabled-services` Application.
* **Trigger:** `PostSync`
* **Behavior:** This runs automatically after the pods are restarted, confirming the new mesh version is handling traffic correctly.

### **Changes Required**
* [ ] Split current python verification script into modular, standalone CLI tools that return `Exit Code 1` on failure.
* [ ] Update ArgoCD Helm charts/manifests to include `Job` resources with `argocd.argoproj.io/hook: PostSync` annotations.
* [ ] Update Docker image for `af-toolkit` to include the refactored scripts.

### **Acceptance Criteria**
1.  **Control Plane Safety:** If `verify_controlplane.py` fails, the pipeline stops, and no application pods are restarted.
2.  **Visibility:** ArgoCD UI visually distinguishes between a Control Plane failure and a Data Plane failure.
3.  **Automation:** The verification runs automatically upon syncing the respective applications, removing manual trigger steps.
4.  **Cleanup:** The "Prune" steps (deleting old Istio versions) remain manual/separate for safety (Soak Period).

### **Notes**
* *Pruning Strategy:* We will **not** automate the deletion of the old Control Plane in this ticket to allow for a rollback window (Soak Period).

---

### **Would you like me to draft the "Phase 1" YAML definition for the `istiod` hook so you can attach it to the ticket?**


Here is the detailed breakdown for your Jira ticket, plus a technical analysis of using `istioctl x precheck` as a `PreSync` hook.

### **Jira Ticket Section: Current vs. Proposed Flow**

You can copy-paste this section directly into the "Description" or "Technical Approach" field of your Jira ticket. It clearly contrasts the risk of the current approach with the safety of the new one.

-----

#### **1. Current Flow (The "Verify-at-End" Model)**

Currently, verification happens only after the entire upgrade process is effectively complete.

1.  **Sync `istio-base` & `istiod`**: ArgoCD syncs the Control Plane.
2.  **Sync `istio-ingress`**: ArgoCD syncs the Ingress Gateways.
3.  **Restart Workloads**: Run the `sequential-restart-all-istio-enabled-services` job to roll every sidecar.
4.  **Manual Trigger**: Engineer manually triggers the `verify-istio` job in the `af-toolkit` namespace.
5.  **Monolithic Verification**: The script runs all checks (Control Plane health, Ingress access, mTLS, EnvoyFilters) in one go.
      * **Risk:** If `istiod` was unhealthy at Step 1, we don't realize it until Step 5. By then, we have already restarted all workloads (Step 3), potentially causing a massive outage with broken sidecars.

#### **2. Proposed Flow (The "Fail-Fast" Model)**

We split the monolithic job into granular **ArgoCD Hooks** to gate each stage.

**Stage A: Pre-Flight (New)**

  * **Hook:** `PreSync` on `istiod` Application.
  * **Action:** Run `istioctl x precheck`.
  * **Outcome:** If this detects upgrade incompatibility (e.g., deprecated APIs in use), the sync **aborts immediately**. No changes are applied to the cluster.

**Stage B: Control Plane Verification**

  * **Hook:** `PostSync` on `istiod` Application.
  * **Action:** Run `verify_controlplane.py` (Check `istiod` deployment, staled proxy status, `istioctl analyze`).
  * **Outcome:** If `istiod` is unhealthy, the pipeline stops. **We do NOT proceed to Ingress or Workload restarts.** The cluster remains on the old data plane (safe).

**Stage C: Ingress Verification**

  * **Hook:** `PostSync` on `istio-ingress` Application.
  * **Action:** Run `check_ingress_gateway.py` (Verify external connectivity).
  * **Outcome:** Verifies that North-South traffic works before we touch East-West traffic.

**Stage D: Data Plane Verification**

  * **Hook:** `PostSync` on the `sequential-restart` Application.
  * **Action:** Run `check_mtls.py` and `check_retry_after.py`.
  * **Outcome:** Runs automatically *after* workloads restart, confirming the new sidecars are enforcing mTLS and EnvoyFilters correctly.

-----

### **Deep Dive: Can we use `istioctl x precheck` as a PreSync Hook?**

**Yes, absolutely.** This is an excellent use case for a `PreSync` hook.

#### **Why `PreSync`?**

  * **Purpose:** `istioctl x precheck` is designed to run *before* you apply the new Istio version. It checks if your *current* cluster configuration (CRDs, APIs) is compatible with the *target* Istio version.
  * **Behavior:** If you put this in a `PostSync` hook, it’s too late—you’ve already upgraded. By placing it in `PreSync`, if the check fails (returns non-zero exit code), ArgoCD will **block the sync**. The new `istiod` manifests will never be applied, keeping your cluster in a known good state.

#### **Implementation Details**

To make this work in ArgoCD, the job needs two things:

1.  **Permissions:** A ServiceAccount with ample read permissions (ClusterRole) to check CRDs, Webhooks, and Namespaces.
2.  **Target Version:** You must pass the target version to the command so it knows what to check against.

**Sample YAML for the PreSync Job:**

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  generateName: istio-precheck-
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
spec:
  template:
    spec:
      serviceAccountName: istio-verification-sa # Needs read-access to cluster
      containers:
      - name: precheck
        image: istio/istioctl:1.24.0 # Use the VERSION you are upgrading TO
        command:
        - /bin/sh
        - -c
        - |
          # Run precheck against the version of the binary (1.24.0)
          # We use --from-version if we want to simulate an upgrade from a specific old version
          istioctl x precheck 
      restartPolicy: Never
```

### **Summary of Benefits for the Team**

1.  **Safety:** We stop "bad upgrades" before they happen (`PreSync`) or before they spread (`PostSync` on Control Plane).
2.  **Clarity:** When the pipeline fails, we know exactly *where* (Pre-check? Control Plane? Data Plane?) without reading 500 lines of logs.
3.  **Automation:** No more "waiting for the slack message to tell me to run the verification job."